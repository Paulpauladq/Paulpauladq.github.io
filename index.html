<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Machine Learning by Andrew NG" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/02/Machine Learning by Andrew NG/" class="article-date">
  <time datetime="2018-04-02T07:29:46.601Z" itemprop="datePublished">2018-04-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>title: Machine Learning by Andrew NG</p>
<h1 id="Machine-Learning-by-Andrew-NG"><a href="#Machine-Learning-by-Andrew-NG" class="headerlink" title="Machine Learning by Andrew NG"></a>Machine Learning by Andrew NG</h1><h2 id="Prioritizing-what-to-work-on-Spam-classification-example"><a href="#Prioritizing-what-to-work-on-Spam-classification-example" class="headerlink" title="Prioritizing what to work on: Spam classification example"></a>Prioritizing what to work on: Spam classification example</h2><ol>
<li><strong>Example</strong>: spam classification</li>
<li>Steps to work on: <ul>
<li>Supervised learning</li>
<li>Listing all the possible features(choose 100 indicative words)</li>
<li>Build a classification vector based on features</li>
</ul>
</li>
<li>Improve the <strong>accuracy</strong>:<ul>
<li>Collect lots of data</li>
<li>Develop sophisticated features</li>
<li>Develop algorithms to process your input in different ways</li>
</ul>
</li>
</ol>
<h2 id="Error-Analysis"><a href="#Error-Analysis" class="headerlink" title="Error Analysis"></a>Error Analysis</h2><ol>
<li>Start with a simple algorithm, implement it quickly, and test it early on your cross validation data.</li>
<li>Plot learning curves to decide if more data, more features, etc. are likely to help.</li>
<li>Manually examine the errors on examples in the cross validation set and try to spot a trend where most of the errors were made.</li>
<li>get error results as a <strong>single, numerical</strong> value.</li>
</ol>
<h2 id="Error-Metrics-for-Skewed-Data"><a href="#Error-Metrics-for-Skewed-Data" class="headerlink" title="Error Metrics for Skewed Data"></a>Error Metrics for Skewed Data</h2><ol>
<li><strong>Error Metrics</strong>: </li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th style="text-align:left">Actual Class</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td style="text-align:left">1</td>
<td>0</td>
</tr>
<tr>
<td>Predicted Class</td>
<td>1</td>
<td style="text-align:left">True positive</td>
<td>False Positive</td>
</tr>
<tr>
<td></td>
<td>0</td>
<td style="text-align:left">False negative</td>
<td>True negative</td>
</tr>
</tbody>
</table>
<ol start="2">
<li><strong>Precision</strong>: = true positive/predicted class = true pos/ true pos + false pos</li>
<li><strong>Recall</strong>: = true pos/actual class = true pos + false neg</li>
<li><strong>Tradeoff</strong> between P and R: $F_1$ Score(F Score): 2 <em> P </em> R/ ( P + R)</li>
<li>Tackle with <strong>Large data rationale</strong>:<ul>
<li>Use a learning algorithm w/ many parameters ( guarantee low bias) </li>
<li>Use a very large training set (guarantee low variance)</li>
</ul>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/02/Machine Learning by Andrew NG/" data-id="cjfrmokxx0002csvj20s4trk7" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/02/Hadoop/" class="article-date">
  <time datetime="2018-04-02T07:29:45.088Z" itemprop="datePublished">2018-04-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>title: Hadoop</p>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="MapReduce-Mechanism"><a href="#MapReduce-Mechanism" class="headerlink" title="MapReduce Mechanism"></a>MapReduce Mechanism</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><ol>
<li>Map: 将数据集分成独立的块，每个快由map任务平行执行</li>
<li>Reduce: 框架将map的输出排序并输入到reduce任务中</li>
<li>工作的输入和输出都被存储在文件系统之中</li>
<li>框架的作用:<ul>
<li>规划任务</li>
<li>监督任务</li>
<li>重新执行失败的任务</li>
</ul>
</li>
<li>compute nodes 和 storage nodes是同一个，即MapReduce和HDFS在同一组节点上运行。这种设定可以允许框架高效地在数据显示地地方执行工作，在集群中获得较高的带宽</li>
<li>Framework:<ul>
<li>a single master – ResourceManager</li>
<li>one slave NodeManager per cluster-node</li>
<li>MRAppMaster per application</li>
</ul>
</li>
<li>分布式执行的方式：<ul>
<li>应用制定输入输出的和地址，通过实现接口来提供 map，reduce函数</li>
<li>hadoop job client将job以及相关的configuration提交给ResourceManager</li>
<li>ResourceManager将任务分发给slave NodeManager，进行一系列监控和安排操作</li>
</ul>
</li>
</ol>
<h3 id="Inputs-and-Outputs"><a href="#Inputs-and-Outputs" class="headerlink" title="Inputs and Outputs"></a>Inputs and Outputs</h3><ol>
<li><p>MapReduce函数只通过键值对进行操作（通过键值对进行输入以及输出）</p>
</li>
<li><p>Input and Output types of a MapReduce job:</p>
<p>(input) <code>&lt;k1, v1&gt; -&gt;</code> <strong>map</strong> <code>-&gt; &lt;k2, v2&gt; -&gt;</code> <strong>combine</strong> <code>-&gt; &lt;k2, v2&gt; -&gt;</code> <strong>reduce</strong> <code>-&gt; &lt;k3, v3&gt;</code> (output)</p>
</li>
<li><p>key和value类需要被框架进行排序，同时需要<strong>实现Writable的接口</strong>，同时，key类需要实现WritableComparable接口使得框架可以对map的输入进行排序</p>
</li>
</ol>
<h3 id="MapReduce-Mechanism-1"><a href="#MapReduce-Mechanism-1" class="headerlink" title="MapReduce Mechanism"></a>MapReduce Mechanism</h3><ol>
<li><strong>Input Split</strong>: 根据输入文件计算输入分片，每个分片的大小和HDFS中的块的关系很密切</li>
<li>Map阶段：为程序员编写</li>
<li>Combiner阶段：是Map运算的后续操作，主要是在Map计算出中间文件之前进行简单的合作重复键值的操作</li>
<li>Shuffle阶段：</li>
<li>Reduce阶段：为程序员编写</li>
</ol>
<ol start="6">
<li>与MapReduce相关的<strong>独立的实体</strong>： <ul>
<li>the client: 用于配置和提交job</li>
<li>the JobTracker: 初始化作业，分配作业，协调整个作业的执行</li>
<li>TaskTracker: 在JobTracker分配的数据片段上执行Map或Reduce任务，</li>
<li>HDFS: 储存作业的数据以及配置信息等</li>
</ul>
</li>
</ol>
<p><img src="C:\Users\pault\Desktop\MapReduce.PNG" alt="MapReduce"></p>
<h3 id="Example-WordCount"><a href="#Example-WordCount" class="headerlink" title="Example: WordCount"></a>Example: WordCount</h3><p>Assume one file of the input text is as follows:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello World Bye World</span><br></pre></td></tr></table></figure>
<ol>
<li>public void map: mapper通过map方法来实现，每次对一行进行操作，将每行用空格分隔成tokens</li>
</ol>
<p>，输出键值对，结果如下（没有排序）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt; Hello, 1&gt;</span><br><span class="line">&lt; World, 1&gt;</span><br><span class="line">&lt; Bye, 1&gt;</span><br><span class="line">&lt; World, 1&gt;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>job.setCombinerClass(IntSumReducer.class): 每个map的输出传入本地的combiner（只针对每个文件）中，结果如下(对于key有排序)：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt; Bye, 1&gt;</span><br><span class="line">&lt; Hello, 1&gt;</span><br><span class="line">&lt; World, 2&gt;</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>public void reduce: 将所有文件中的键值对一起合并起来</li>
</ol>
<h2 id="HDFS-Architecture"><a href="#HDFS-Architecture" class="headerlink" title="HDFS Architecture"></a>HDFS Architecture</h2><ol>
<li><p><strong>NameNode</strong>: a single Namenode, “Master” that manage the file system namespace and regulates access to files by clients.</p>
</li>
<li><p><strong>DataNodes</strong>: “Slaves”, usually one per node in the cluster that manage storage attached to the nodes that they run on.</p>
</li>
<li><p><strong>Heartbeat</strong>: a signal used between a data node and a slave node（NameNode周期性接收DataNode的信号，如果JobTracker没有接受到信号，则TaskTracker存在一定的问题）</p>
</li>
<li><p><strong>File System Namespace</strong>: HDFS supports a traditional hierarchical file organization.</p>
</li>
<li><p><strong>Data Replication</strong>: </p>
<ul>
<li><p>stores each file as a sequence of blocks(are <strong>replicated</strong> for fault tolerance). </p>
</li>
<li><p>An application can specify the number of replicas of a file.</p>
</li>
<li><p>Files in HDFS are write-once.</p>
<p>​</p>
</li>
</ul>
</li>
</ol>
<h2 id="YARN-Architecture"><a href="#YARN-Architecture" class="headerlink" title="YARN Architecture"></a>YARN Architecture</h2><h2 id="Apache-Mahout"><a href="#Apache-Mahout" class="headerlink" title="Apache Mahout"></a>Apache Mahout</h2><h3 id="Recommendations"><a href="#Recommendations" class="headerlink" title="Recommendations"></a>Recommendations</h3><ol>
<li>Defining Recommendation: User-based/ item-based / content-based</li>
<li><p>Running a first recommender engine:</p>
<ul>
<li>Create a recommender input file – intro.csv </li>
<li>Create a recommender</li>
</ul>
</li>
<li><p>Components of a recommender engine:</p>
<ul>
<li>UserSimilarity: 提供了两者的相似程度</li>
<li>UserNeighborhood: 提供了一组和某个特定用户相近的用户群</li>
<li>DataModel: 储存和保证所有数据被执行</li>
<li>Recommender: 将所有的组件集合起来</li>
</ul>
</li>
<li>​</li>
</ol>
<h1 id="Databases"><a href="#Databases" class="headerlink" title="Databases"></a>Databases</h1><h2 id="Database-Selection"><a href="#Database-Selection" class="headerlink" title="Database Selection"></a>Database Selection</h2><h3 id="数据库仓库系统"><a href="#数据库仓库系统" class="headerlink" title="数据库仓库系统"></a>数据库仓库系统</h3><p>数据仓库系统是指具有综合企业数据的能力，能够对大量企业数据进行快速和准确分析，辅助做出更好的商业决策的系统。它本身包括三部分内容：</p>
<ol>
<li><a href="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E5%B1%82" target="_blank" rel="noopener">数据层</a>：实现对企业操作数据的抽取、转换、清洗和汇总，形成信息数据，并存储在企业级的中心信息数据库中。</li>
<li><a href="https://baike.baidu.com/item/%E5%BA%94%E7%94%A8%E5%B1%82/4329788" target="_blank" rel="noopener">应用层</a>：通过联机分析处理，甚至是数据挖掘等应用处理，实现对信息数据的分析。</li>
<li>表现层：通过前台分析工具，将查询报表、统计分析、多维联机分析和数据发掘的结论展现在用户面前。</li>
</ol>
<h2 id="Pattern-Tradeoff"><a href="#Pattern-Tradeoff" class="headerlink" title="Pattern Tradeoff"></a>Pattern Tradeoff</h2><h3 id="OLTP"><a href="#OLTP" class="headerlink" title="OLTP"></a>OLTP</h3><ol>
<li>Definition: <strong>传统数据库侧重交易处理，即OLTP</strong>，关注的是多用户的同时的双向操作，在保障即时性的要求下，系统通过内存来处理数据的分配、读写等操作，存在IO瓶颈。</li>
<li><p>特点：</p>
<ul>
<li>数据在系统中产生</li>
<li>基于交易的处理系统</li>
<li>每次交易牵涉的数据量很小</li>
<li>对响应时间要求很高</li>
</ul>
<p>​</p>
</li>
</ol>
<h3 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h3><ol>
<li>Definition: <strong>分析型数据库是以实时多维分析技术作为基础，即侧重OLAP</strong>，对数据进行多角度的模拟和归纳，从而得出数据中所包含的信息和知识。</li>
<li><p>特点：</p>
<ul>
<li><p>本身不产生数据</p>
</li>
<li><p>基于查询的分析系统</p>
<p>​</p>
</li>
</ul>
</li>
</ol>
<h2 id="Apache-Storm"><a href="#Apache-Storm" class="headerlink" title="Apache Storm"></a>Apache Storm</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ol>
<li><p>What is Storm?</p>
<p>Apache Storm is a distributed real-time big data-processing system.</p>
</li>
<li><p>Apache Storm versus. Hadoop:</p>
</li>
</ol>
<table>
<thead>
<tr>
<th>Storm</th>
<th>Hadoop</th>
</tr>
</thead>
<tbody>
<tr>
<td>Real-time stream processing</td>
<td>Batch processing</td>
</tr>
<tr>
<td>Stateless</td>
<td>Stateful</td>
</tr>
<tr>
<td>Master/Slave architecture with ZooKeeper based coordination. The master node is called as <strong>nimbus</strong> and slaves are <strong>supervisors</strong>.</td>
<td>Master-slave architecture with/without ZooKeeper based coordination. Master node is <strong>job tracker</strong> and slave node is <strong>task tracker</strong>.</td>
</tr>
<tr>
<td>A Storm streaming process can access tens of thousands messages per second on cluster.</td>
<td>Hadoop Distributed File System (HDFS) uses MapReduce framework to process vast amount of data that takes minutes or hours.</td>
</tr>
<tr>
<td>Storm topology runs until shutdown by the user or an unexpected unrecoverable failure.</td>
<td>MapReduce jobs are executed in a sequential order and completed eventually.</td>
</tr>
<tr>
<td><strong>Both are distributed and fault-tolerant</strong></td>
<td></td>
</tr>
<tr>
<td>If nimbus / supervisor dies, restarting makes it continue from where it stopped, hence nothing gets affected.</td>
<td>If the JobTracker dies, all the running jobs are lost.</td>
</tr>
</tbody>
</table>
<h3 id="Core-Concepts"><a href="#Core-Concepts" class="headerlink" title="Core Concepts"></a>Core Concepts</h3><ol>
<li>工作原理：在一端读取实时数据的原始流并传递给一系列无需的处理单元并在另一端输出处理过的信息。</li>
<li>components:</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:center">Components</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Tuple</td>
<td>Tuple is the main data structure in Storm. It is a list of ordered elements. By default, a Tuple supports all data types. Generally, it is modelled as a set of comma separated values and passed to a Storm cluster. （数据刘中的数据单元，包含着数据）</td>
</tr>
<tr>
<td style="text-align:center">Stream</td>
<td>Stream is an unordered sequence of tuples.（无序的tuple序列）</td>
</tr>
<tr>
<td style="text-align:center">Spouts</td>
<td>Source of stream. Generally, Storm accepts input data from raw data sources like Twitter Streaming API, Apache Kafka queue, Kestrel queue, etc. Otherwise you can write spouts to read data from datasources. “ISpout” is the core interface for implementing spouts. Some of the specific interfaces are IRichSpout, BaseRichSpout, KafkaSpout, etc.（数据流的源头，通过Spouts从数据源读取数据）</td>
</tr>
<tr>
<td style="text-align:center">Bolts</td>
<td>Bolts are logical processing units. Spouts pass data to bolts and bolts process and produce a new output stream. Bolts can perform the operations of filtering, aggregation, joining, interacting with data sources and databases. Bolt receives data and emits to one or more bolts. “IBolt” is the core interface for implementing bolts. Some of the common interfaces are IRichBolt, IBasicBolt, etc.（处理单元，可以有多个）</td>
</tr>
</tbody>
</table>
<ol start="3">
<li><p>topology: spout 和bolts 共同形成拓扑，使用时需要把整个拓扑图构造出来</p>
<ul>
<li>定义数据从哪儿来</li>
<li>定义数据流向和处理单元的逻辑</li>
<li>定义数据到哪里去</li>
</ul>
</li>
<li><p>Tasks: 即任务，一个task就是一个Spout的执行或者一个Bolt的执行</p>
</li>
<li><p>Workers: 即工作进程，负责实际运行task；topology运行在一个分布式环境中的多个节点上，Storm会把tasks均匀分布在所有worker（每个Worker都是一个物理JVM执行这拓扑中所有task的子集）上</p>
</li>
<li><p>Stream Grouping: 定义tuple在topology中如何流动，常见的4种常用的分组策略：</p>
<ul>
<li>Shuffle Grouping：随机分配，可以让每个bolt中的worker获得数量均衡的Tuple</li>
<li>Field Grouping: 根据field名字来分配，某个field分组，名字相同的tuples会被组织在一起</li>
<li>Global Grouping: 全局统一分组，所有数据流都流向同一个Worker</li>
<li>All Grouping:  向每个实例都发送一次</li>
</ul>
<p>​</p>
</li>
</ol>
<h3 id="Cluster-Architecture"><a href="#Cluster-Architecture" class="headerlink" title="Cluster Architecture"></a>Cluster Architecture</h3><ol>
<li>节点：storm cluster中有2中类型节点：master node 和 worker node</li>
<li><strong>Nimbus</strong>: Master node 中运行着一个守护进程，负责向集群中分布代码、分配任务、监控失败状况</li>
<li><strong>Supervisor</strong>: 每个worker node运行的daemon，负责接受工作任务，根据nimbus的指令来启动或者停止工作进程</li>
<li>协作：nimbus(stateless)和supervisor(stateless)之间的协作是通过zookeeper集群完成的</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/02/Hadoop/" data-id="cjfrmokxu0001csvjmznvhovc" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Face_Tracking_Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/02/Face_Tracking_Notes/" class="article-date">
  <time datetime="2018-04-02T07:29:40.888Z" itemprop="datePublished">2018-04-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/02/Face_Tracking_Notes/">Face Tracking</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Face-Tracking"><a href="#Face-Tracking" class="headerlink" title="Face Tracking"></a>Face Tracking</h1><h2 id="Face-Detection-and-Tracking-Using-the-KLT-Algorithm"><a href="#Face-Detection-and-Tracking-Using-the-KLT-Algorithm" class="headerlink" title="Face Detection and Tracking Using the KLT Algorithm"></a>Face Detection and Tracking Using the KLT Algorithm</h2><ol>
<li><p>脸部追踪（甚至该人倾斜他的头，移动或者头部离相机很远的时候）</p>
</li>
<li><p>使用feature points</p>
</li>
<li><p>脸部追踪的三步：</p>
<ul>
<li>面部检测</li>
<li>定义追踪的特征</li>
<li>追踪</li>
</ul>
</li>
<li><p>首先使用Viola-Jones detection algorithm进行人脸检测，随后使用minimum eigenvalue算法提取features</p>
</li>
<li><p><strong>Thinking</strong>：</p>
<ul>
<li>Face detection focuses more on the <strong>detection accuracy</strong>, whereas face tracking pays more attention to the detection <strong>time cost</strong> because most face tracker needs to achieve real-time properties.</li>
<li>We can improve the time performance by optimizing each step of face tracking, since we already had the state-of-the-art face detection technics, we narrow down our work to optimizing the last 2 steps.</li>
</ul>
</li>
<li><p><strong>Question</strong>: the classic algorithm and CNN method, which one is better on real-time solution?</p>
<p>​</p>
</li>
</ol>
<h2 id="Viola-amp-Jones-Face-Detection"><a href="#Viola-amp-Jones-Face-Detection" class="headerlink" title="Viola&amp;Jones Face Detection"></a>Viola&amp;Jones Face Detection</h2><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf" target="_blank" rel="noopener">https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf</a></p>
<h3 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h3><ol>
<li>新方法优点：<ul>
<li>速度极快</li>
<li>准确率极高</li>
</ul>
</li>
<li>主要contribution:<ul>
<li>Integral Image</li>
<li>Adaboost算法提取features</li>
<li>cascade级联结合复杂分类器的方法</li>
</ul>
</li>
</ol>
<h3 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h3><ol>
<li>Harr-like features: 双/多矩形feature，计算两/多个相邻矩形像素和的差值</li>
<li>问题所在：太多冗余（无用）features</li>
</ol>
<h3 id="Integral-Image"><a href="#Integral-Image" class="headerlink" title="Integral Image"></a>Integral Image</h3><ol>
<li>Definition: ii(x,y) calculates the sum of pixels above and to the left of x,y, inclusive</li>
<li>The sum with D: 4+1-2-3 (Figure 2)</li>
</ol>
<h3 id="Learning-Classification-Functions"><a href="#Learning-Classification-Functions" class="headerlink" title="Learning Classification Functions"></a>Learning Classification Functions</h3><ol>
<li><p>Motivation: 24 x 24的图片具有超过180000种features，大多数没有用，需要筛选出有用的features</p>
</li>
<li><p>分类学习时使用Adaboost算法:</p>
<ul>
<li><p>初始化训练数据的权值分布，开始时每个样本权值相同。</p>
<p>$D_t(i) = (w_1, w_2, … , w_n) = (1/N,….,1/N)$</p>
</li>
<li><p>对每个特征j，训练一个弱分类器，计算在分布$D_t$上的误差，选择误差最小的弱分类器，更新训练数据寄的权值分布，用于下一轮的迭代(增加误分类样本的权值，减小正确分类样本的权值)</p>
</li>
<li><p>组合各个弱分类器，使用sign函数得到最终分类器</p>
</li>
<li><p>计算复杂度：O(MNT), M filters/ N examples/ T thresholds</p>
</li>
</ul>
</li>
<li><p>Adaboost选出的前几个feature是： 眼睛部分比脸颊部分颜色深</p>
<ul>
<li>眼睛部分比鼻梁部分颜色深</li>
</ul>
</li>
</ol>
<h3 id="Cascading-Classifiers"><a href="#Cascading-Classifiers" class="headerlink" title="Cascading Classifiers"></a>Cascading Classifiers</h3><ol>
<li>级联消除negative samples</li>
</ol>
<h2 id="Good-Features-to-Track"><a href="#Good-Features-to-Track" class="headerlink" title="Good Features to Track"></a>Good Features to Track</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><ol>
<li>问题：tracking已经实现，但是选择容易被追踪的特征很难</li>
<li>提出：<ul>
<li>基于tracker工作的特征选择的标准</li>
<li>一个特征检测器</li>
<li>和现实世界无关的特征</li>
</ul>
</li>
</ol>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ol>
<li>SSD: sum-of -squared-difference(SSD) methods ??</li>
<li><p><strong>Feature Dissimilarity</strong>: </p>
<ul>
<li>Definition: the quantity that describes <strong>the changes of appearance of a feature (rms residue)</strong> between the 1st frame and the current frame</li>
<li><strong>RMS RESIDUE</strong>: google look up</li>
<li>Idea: When the dissimilarity grows too large, the feature is a “bad” one. </li>
</ul>
</li>
<li><p><strong>Affine</strong> image changes: linear warping and transforming the image</p>
</li>
<li><p>2 main contributions:</p>
<ul>
<li>Prove that for <strong>measure dissimilarity</strong> : pure translation–NOT ADEQUATE; affine image changes–ADEQUATE</li>
<li>Propose a GOOD way to determine the affine changes</li>
<li>extra: a more PRINCIPLED way to select features</li>
</ul>
</li>
<li><p>Result:</p>
<ul>
<li><p>2 models of image motion &gt; 1model</p>
</li>
<li><p><strong>Dependency</strong>: </p>
<ul>
<li>inter-frame camera translation is small – pure translation</li>
<li>distant frames – affine changes</li>
</ul>
</li>
</ul>
</li>
<li>思考：frame中的物体变换较小，pure translation在节省计算量的情况下，可以保持较为不错的准确度，此时采用affine image changes追踪到的参数不可靠，但是物体移动很快时，affine image changes是必须的</li>
</ol>
<h3 id="Two-Models-of-Image-Motion"><a href="#Two-Models-of-Image-Motion" class="headerlink" title="Two Models of Image Motion"></a><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\GFTT_35.PNG" alt="GFTT_35">Two Models of Image Motion</h3><ol>
<li>pure translation: tracking</li>
<li>affine changes: compare feature to monitor</li>
</ol>
<h3 id="Computing-Image-Motion"><a href="#Computing-Image-Motion" class="headerlink" title="Computing Image Motion"></a>Computing Image Motion</h3><ol>
<li><p>Details can be found in the <strong>derivation process</strong>.</p>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\WeChat Image_20171221210136.jpg" alt="WeChat Image_20171221210136"></p>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\WeChat Image_20171221210131.jpg" alt="WeChat Image_20171221210131"></p>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\WeChat Image_20171221210127.jpg" alt="WeChat Image_20171221210127"></p>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\WeChat Image_20171221210114.jpg" alt="WeChat Image_20171221210114"></p>
<p>​</p>
</li>
<li><p>We divide all the circumstances into two separate parts:</p>
<ul>
<li>During tracking, the affine deformation D of the feature window is small, so we set D to 0 matrix. In such cases, we solve Zd = e.</li>
<li>During feature monitoring, motion is too large to be described well by pure translation, the entire transformation Tz = a needs to be solved.</li>
</ul>
</li>
</ol>
<h3 id="Texturedness"><a href="#Texturedness" class="headerlink" title="Texturedness"></a>Texturedness</h3><ol>
<li>Problems aimed to be solved: motions are not <strong>complete</strong></li>
<li>Typical solution: track corners or windows with a high spatial frequency content(????), or regions where second-order derivatives is high(??????). But there exists 2 problems:<ul>
<li>Intuitive and preconceived, their methods aren’t guarantee to be best for tracking</li>
<li>usually defined for the pure translation model, hard to extend them to affine motion</li>
</ul>
</li>
<li>PRINCIPLED DEFINITION OF <strong>FEATURE QUALITY</strong></li>
<li>(????????) 对于Z的两个特征值，Accept a window if: $min(\lambda_1, \lambda_2 ) &gt; \lambda$</li>
</ol>
<h3 id="Dissimilarity"><a href="#Dissimilarity" class="headerlink" title="Dissimilarity"></a>Dissimilarity</h3><h3 id="Simulations"><a href="#Simulations" class="headerlink" title="Simulations"></a>Simulations</h3><h3 id="Python-Implementation"><a href="#Python-Implementation" class="headerlink" title="Python Implementation"></a>Python Implementation</h3><ol>
<li><p>A simple demo of python:选择一副图片，使用opencv的good features to track算法可以清楚的提取出高质量的特征点，这里选择如下的含有明显“好的”（棱角分明）特征的图片，便于观察效果，使用python实现算法，并且分别设置获取特征点的个数为25,35,45,200:</p>
<p>​</p>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\GFTT_25.PNG" alt="GFTT_25"></p>
<p>​</p>
</li>
</ol>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\GFTT_35.PNG" alt="GFTT_35"></p>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\GFTT_45.PNG" alt="GFTT_45"></p>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\GFTT_200.PNG" alt="GFTT_200"></p>
<p>由上面的实验结果可以观察到特征提取的结果较为良好，直观来看提取的点都在边缘上。</p>
<ul>
<li>思考：<ol>
<li>后续的实验可以采用规范化的特征来评估“好”的程度，便于量化goodness，以及便于和其他优化算法比对。</li>
<li>使用Python的实现，只能在图片上显示track的效果，但不能清楚地看到每个被提取点的”Goodness”值</li>
</ol>
</li>
</ul>
<h3 id="A-implementation-of-the-KLT-Feature-Tracker-C"><a href="#A-implementation-of-the-KLT-Feature-Tracker-C" class="headerlink" title="A implementation of the KLT Feature Tracker(C++)"></a>A implementation of the KLT Feature Tracker(C++)</h3><ol>
<li><p>Home page: <a href="http://cecas.clemson.edu/~stb/klt/" target="_blank" rel="noopener">http://cecas.clemson.edu/~stb/klt/</a></p>
</li>
<li><p>这是网上已经实现好的KLT tracker，解决了上面自己实现的问题，在Linux上运行可以选择一副图片提取特征点并且可以按照每个特征点的goodness值打印出所有被提取点的坐标，结果如下：</p>
<p><img src="C:\Users\Paul\Desktop\Face Tracking\Images\GFTT\example1.PNG" alt="example1"></p>
</li>
</ol>
<h2 id="An-Iterative-Image-Registration-Technique-with-an-Application-to-Stereo-Vision"><a href="#An-Iterative-Image-Registration-Technique-with-an-Application-to-Stereo-Vision" class="headerlink" title="An Iterative Image Registration Technique with an Application to Stereo Vision"></a>An Iterative Image Registration Technique with an Application to Stereo Vision</h2><h3 id="The-Registration-Problem"><a href="#The-Registration-Problem" class="headerlink" title="The Registration Problem"></a>The Registration Problem</h3><ol>
<li>Problem: F(x) and G(x) gives the corresponding pixel value for location x in two different images. Our goal is to find out the <strong>disparity</strong> vector h that minimizes of the difference between F(x + h) and G(x) in Region of Interest R</li>
<li>Typical Solution: $L_1 norm$, $L_2 norm$, negative of normalized correlation</li>
</ol>
<h3 id="The-Registration-Algorithm"><a href="#The-Registration-Algorithm" class="headerlink" title="The Registration Algorithm"></a>The Registration Algorithm</h3><ol>
<li>One-D case</li>
<li>2D Case</li>
</ol>
<h2 id="The-First-Facial-Landmark-Tracking-in-the-Wild-Challenge-Benchmark-and-Results"><a href="#The-First-Facial-Landmark-Tracking-in-the-Wild-Challenge-Benchmark-and-Results" class="headerlink" title="The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results"></a>The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results</h2><h2 id="High-Speed-Tracking-with-Kernelized-Correlation-Filters"><a href="#High-Speed-Tracking-with-Kernelized-Correlation-Filters" class="headerlink" title="High-Speed Tracking with Kernelized Correlation Filters"></a>High-Speed Tracking with Kernelized Correlation Filters</h2><h3 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h3><ol>
<li>重大突破：区别学习方法 – 再有目标的image patch中区分出目标的外貌和背景的外貌</li>
<li>Motivation: <ul>
<li>一个样本中又无限数量的负样本，为了平衡时间和样本数量，一般的做法是再每一帧随机选取几个样本</li>
<li>undersampling会大大降低性能</li>
</ul>
</li>
</ol>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><ol>
<li>tracking-by-detection：</li>
<li>On sample translation and correlation filtering </li>
</ol>
<h3 id="Building-Blocks"><a href="#Building-Blocks" class="headerlink" title="Building Blocks"></a>Building Blocks</h3><ol>
<li>Linear regression(线性回归训练提速):   </li>
</ol>
<p>###Code Analysis </p>
<ol>
<li><p>choose_video.m: </p>
<ul>
<li>功能：选择视频的种类</li>
</ul>
</li>
</ol>
<ul>
<li>参数： base_path（视频路径）</li>
<li>函数实现细节：<ul>
<li>确认视频路径统一</li>
<li>列出所有子目录</li>
<li>显示GUI，让用户选择</li>
</ul>
</li>
</ul>
<ol start="2">
<li><p>download_videos.m: 下载视频，解压到固定路径</p>
</li>
<li><p>fhog.m: </p>
<ul>
<li>功能：计算FHOG（改良版HOG特征）</li>
<li>输入参数：<ul>
<li>I: 输入图片</li>
<li>binSize: bin的大小</li>
<li>nOrients: 有方向的bin的个数</li>
<li>clip: 剪切</li>
<li>crop: 是否剪辑边缘</li>
</ul>
</li>
<li>输出：计算出的函数</li>
</ul>
</li>
<li><p>gaussian_correlation.m: </p>
<ul>
<li>功能：计算高斯内核函数</li>
<li>输入参数：<ul>
<li>xf,yf: 傅里叶空间中的输入图片x,y（都是m x n）</li>
<li>sigma: bandwidth（常参数）</li>
</ul>
</li>
<li>输出：一个m x n的响应图</li>
</ul>
</li>
<li><p>gaussian_shaped_labels.m:</p>
<ul>
<li>功能：为每个样本的所有shifts建立一个标签队列（回归目标）</li>
<li>输入参数：<ul>
<li>sigma: const</li>
<li>sz: 标签数组大小</li>
</ul>
</li>
<li>输出：大小为SZ（shift数量）的标签数组</li>
</ul>
</li>
<li><p>get_features.m:</p>
<ul>
<li>功能：从图片中提取特征</li>
<li>输入参数：<ul>
<li>im: 输入图片</li>
<li>features: 采集的特征（HOG特征或者是灰度特征）</li>
<li>cell_size: cell的大小</li>
<li>cos_window: 添加汉宁窗使得图像边缘平滑</li>
</ul>
</li>
<li>输出：数组x – [cell的高度， cell的宽度，特征向量]</li>
</ul>
</li>
<li><p>get_subwindows.m:</p>
<ul>
<li>功能：获得子窗口</li>
<li>输入参数:<ul>
<li>im: 提取的图片</li>
<li>pos: 子窗口的中心</li>
<li>sz: 子窗口的长宽（如果子窗口到了图片外面则复制边缘像素来填充空白）</li>
</ul>
</li>
<li>输出：提取出的子窗口区域(ys ,xs ,:)</li>
</ul>
</li>
<li><p>linear_correlation.m:</p>
<ul>
<li>功能: 计算输入线性内核函数</li>
<li>输入参数：xf,yf: 傅里叶空间中的输入图片x,y（都是m x n）</li>
<li>输出：m x n的响应图谱</li>
</ul>
</li>
<li><p>load_video_info.m:</p>
<ul>
<li>功能：加载指定路径中的所有视频的相关性信息</li>
<li>输入参数：视频存放路径，视频名称</li>
<li>输出：各种相关信息<ul>
<li>img_files: 图片文件的数组</li>
<li>pos: 起始位置坐标</li>
<li>target_sz: 目标大小</li>
<li>ground_truth: N帧中gt的位置</li>
<li>video_path: 视频存放的路径</li>
</ul>
</li>
</ul>
</li>
<li><p>polynomial_correlation.m:</p>
<ul>
<li>功能：在所有shifts上计算多项式内核</li>
<li>输入参数：<ul>
<li>xf,yf: m x n的输入图像</li>
<li>a: 多项式内核的常数</li>
<li>b: 多项式内核的指数</li>
</ul>
</li>
<li>输出：一个m x n的响应图</li>
</ul>
</li>
<li><p>precision_plot.m: </p>
<ul>
<li>功能：绘制precision/threshold的图形曲线</li>
<li>输入参数：<ul>
<li>positions: 在每一帧（N帧）预测的位置（N * 2） </li>
<li>ground_truth: 在每一帧（N帧）实际的位置（N * 2） </li>
<li>title: 短视频的名称</li>
<li>show: boolean值 – 是否显示曲线</li>
</ul>
</li>
</ul>
</li>
<li><p>run_tracker.m:</p>
<ul>
<li>功能：KCF/DCF的主要接口（设置参数，加载视频，计算准确率以及fps）</li>
<li>输入参数：<ul>
<li>video: 视频类别</li>
<li>kernel_type: 内核类别</li>
<li>feature_type: 特征类别</li>
<li>show_visualization: 是否显示下拉菜单</li>
<li>show_plots: 是否显示曲线图 </li>
</ul>
</li>
<li>输出：无</li>
</ul>
</li>
<li><p>show_video.m:</p>
<ul>
<li>功能：可视化视频段</li>
<li>输入参数：<ul>
<li>img_files: 每一帧的图片文件名称</li>
<li>video_path: 视频路径</li>
<li>resize_image: 是否重置图片大小</li>
</ul>
</li>
<li>输出：UPDATE_VISUALIZATION的函数handle</li>
</ul>
</li>
<li><p>tracker.m:</p>
<ul>
<li><p>功能：实现了kcf/dcf的基本流程</p>
</li>
<li><p>输入参数：</p>
<ul>
<li>video_path: 图片信息被存储的位置</li>
<li>img_files: 是每张图片名称的数组</li>
<li>pos: 目标的起始位置</li>
<li>target_sz: 目标的起始大小</li>
<li>padding: 增加的被追踪的区域相对原本目标的<strong>尺寸</strong></li>
<li>kernel: 决定使用内核种类的一个结构数组（“类型”，“sigma”，“poly_a”，“poly_b”）</li>
<li>lambda: 归一化参数</li>
<li>output_sigma_factor: spatial bandwidth（与目标大小有关）</li>
<li>interp_factor: 追踪器的适应率？？？？</li>
<li>cell_size: 每个cell的像素数量（如果是raw pixel则为1）</li>
<li>features: 决定使用特征种类的一个结构数组</li>
<li>show_visualization: boolean值决定是否显示可交互的视频</li>
</ul>
<p>​</p>
</li>
<li><p>输出：</p>
<ul>
<li>positions: 每一帧的目标位置（N x 2的矩阵）</li>
<li>time: tracker执行的时间</li>
</ul>
</li>
<li><p>实现细节：</p>
<ul>
<li>如果目标个太大，改变图片的尺寸，降低清晰度</li>
<li>设置追踪窗口大小（目标大小加上padding的大小）</li>
<li>使用gaussian_shaped_labels创建循环样本回归的标签yf</li>
<li>使用汉宁窗处理样本</li>
<li>创建视频接口</li>
<li>对于一个视频的每一帧进行循环：读取图片，预处理图片</li>
<li>对于第一帧，选取内核种类，使用单一图片训练模型的系数alphaf（使用kernel计算，按照快速训练公式eq.17）</li>
<li>从第二帧开始取前一帧的子窗口，提取体征并转换到傅里叶空间–zf</li>
<li>对于傅氏空间的特征向量进行内核计算，得出每个shifts的response</li>
<li>对于response进行2d逆傅里叶变换到实数空间，并找到其最大值即检测目标中心点，更新目标位置</li>
<li>使用前一帧的model_alphaf以及model_xf结合新得到的值，更新模型alphaf以及xf</li>
<li>存储每一帧的预测位置和所用时间</li>
</ul>
</li>
</ul>
</li>
<li><p>videofig.m</p>
<ul>
<li>功能：创建一个有水平进度条以及各种快捷键的图像</li>
</ul>
</li>
<li><p>Q&amp;A：</p>
<ul>
<li>response wrap around不明白</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">%target location is at the maximum response. we must take into</span><br><span class="line">%account the fact that, if the target doesn&apos;t move, the peak</span><br><span class="line">%will appear at the top-left corner, not at the center (this is</span><br><span class="line">%discussed in the paper). the responses wrap around cyclically.</span><br><span class="line">[vert_delta, horiz_delta] = find(response == max(response(:)), 1);</span><br><span class="line">if vert_delta &gt; size(zf,1) / 2,  %wrap around to negative half-space of vertical axis</span><br><span class="line">	vert_delta = vert_delta - size(zf,1);</span><br><span class="line">end</span><br><span class="line">if horiz_delta &gt; size(zf,2) / 2,  %same for horizontal axis</span><br><span class="line">	horiz_delta = horiz_delta - size(zf,2);</span><br><span class="line">end</span><br><span class="line">pos = pos + cell_size * [vert_delta - 1, horiz_delta - 1];</span><br></pre></td></tr></table></figure>
<ul>
<li><p>如何生成response map的？</p>
<p>eq.22</p>
</li>
<li><p>labels标注问题！！！！！</p>
<ul>
<li>使用的是高斯label</li>
<li>对于一个短视频的每一帧图片，将它循环平移（水平方向，竖直方向都有），平移间隔为cell宽度（如果是raw pixels则为1)，所以生成的高斯标签为m x n大小，（m x n即原图中的cell个数）</li>
<li>需要将其中响应最高的点移到左上角，方便之后计运算</li>
</ul>
</li>
</ul>
<p>​</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/02/Face_Tracking_Notes/" data-id="cjfrmokxo0000csvj4ze5scs4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/02/hello-world/" class="article-date">
  <time datetime="2018-04-02T07:22:42.501Z" itemprop="datePublished">2018-04-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/02/hello-world/">Hello PPT</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="PPT"><a href="#PPT" class="headerlink" title="PPT"></a>PPT</h2><p>Welcome!</p>
<p>Hello,passengers! This is Paul Tang’s private zone!</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/02/hello-world/" data-id="cjfrmokxy0003csvjnl47e3xu" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/04/02/Machine Learning by Andrew NG/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/04/02/Hadoop/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/04/02/Face_Tracking_Notes/">Face Tracking</a>
          </li>
        
          <li>
            <a href="/2018/04/02/hello-world/">Hello PPT</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>